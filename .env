# ================================================================
# 铃铛师兄大模型博客系统 - 环境变量配置
# ================================================================
# 这是配置示例文件，请根据实际情况修改后使用
# 生产环境请务必修改所有密码和密钥！
# ================================================================

# ================================================================
# LLM 配置
# ================================================================
# 🔔 使用本地 Ollama 进行 Embedding（推荐）
# 优点：完全免费、隐私安全、无需外部 API
# 缺点：需要额外资源（约 2GB 内存）

# Ollama Base URL（Docker 内部地址）
LLM_OLLAMA_BASE_URL=http://ollama:11434

# 是否使用 Ollama 进行 Embedding（true=使用本地，false=使用云端）
LLM_USE_OLLAMA_EMBEDDING=true

# Ollama Embedding 模型名称（需要先下载，见下方说明）
# 推荐：nomic-embed-text（中英文都好，270MB）
LLM_EMBEDDING_MODEL=nomic-embed-text

# ----------------------------------------------------------------
# Chat 模型配置（仍使用火山引擎豆包）
# ----------------------------------------------------------------
# 火山引擎 API Base URL
LLM_BASE_URL=https://ark.cn-beijing.volces.com/api/v3

# 火山引擎 API Key
LLM_API_KEY=12df7044-2100-46fb-bcf5-cff4c5f051c8

# Chat 模型（豆包 Seed1.6 Flash）
LLM_CHAT_MODEL=ep-20250915111522-f87sr

# ================================================================
# 管理员配置（必须配置）
# ================================================================
# 管理员用户名
ADMIN_USERNAME=admin

# 管理员密码（生产环境请使用强密码）
# 生成强密码方法：openssl rand -base64 24
ADMIN_PASSWORD=admin123456

# ================================================================
# JWT 配置（必须配置）
# ================================================================
# JWT 签名密钥（生产环境请使用随机生成的长密钥）
# 生成方法：openssl rand -hex 32
# 示例生成的密钥（64字符）：
JWT_SECRET=a7f3e9d2c1b4a6f8e5d3c9b7a4f2e8d6c3b9a7f4e2d8c6b3a9f7e4d2c8b6a3f9

# JWT 过期时间（毫秒）
# 默认：86400000（24小时）
# JWT_EXPIRATION=86400000

# ================================================================
# 数据库配置（可选，使用默认值）
# ================================================================
# MySQL root 密码
# 生产环境建议使用强密码
DB_PASSWORD=root123456

# ================================================================
# Elasticsearch 配置（可选，使用默认值）
# ================================================================
# Elasticsearch 主机地址
# Docker 环境：elasticsearch
# 本地开发：localhost
ELASTICSEARCH_HOST=elasticsearch

# Elasticsearch 端口
ELASTICSEARCH_PORT=9200

# ================================================================
# 限流配置（可选）
# ================================================================
# Assistant API 每小时允许的请求次数
# 默认：30 次/小时/IP
# 根据实际情况调整（建议 30-100）
RATE_LIMIT_ASSISTANT=360

# ================================================================
# 其他配置示例（当前未使用，预留）
# ================================================================
# 如果使用 Azure OpenAI，配置示例：
# LLM_BASE_URL=https://your-resource.openai.azure.com/openai/deployments
# LLM_API_KEY=your-azure-api-key
# LLM_EMBEDDING_MODEL=your-embedding-deployment-name
# LLM_CHAT_MODEL=your-chat-deployment-name

# 如果使用国内第三方服务（如 DeepSeek、智谱等），配置示例：
# LLM_BASE_URL=https://api.deepseek.com/v1
# LLM_API_KEY=your-deepseek-api-key
# LLM_EMBEDDING_MODEL=deepseek-embedding
# LLM_CHAT_MODEL=deepseek-chat

# 如果使用本地 Ollama，配置示例：
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_API_KEY=ollama
# LLM_EMBEDDING_MODEL=nomic-embed-text
# LLM_CHAT_MODEL=qwen2.5:7b

# ================================================================
# 配置验证清单
# ================================================================
# [ ] LLM_API_KEY 已填写真实有效的 API Key
# [ ] ADMIN_PASSWORD 已修改为强密码（生产环境）
# [ ] JWT_SECRET 已修改为随机生成的密钥（生产环境）
# [ ] DB_PASSWORD 已修改（生产环境）
# [ ] 所有敏感信息已妥善保管，不要提交到公开仓库

# ================================================================
# 快速启动命令
# ================================================================
# 1. 确保已安装 Docker 和 Docker Compose
# 2. 修改上述配置（至少修改 LLM_API_KEY）
# 3. 在项目根目录运行：docker-compose up -d
# 4. 查看日志：docker-compose logs -f
# 5. 访问：http://localhost （前端）
# 6. 管理后台：http://localhost/studio/login

# ================================================================
# 故障排查
# ================================================================
# 如果遇到问题，请检查：
# 1. LLM_API_KEY 是否有效（测试：curl https://api.openai.com/v1/models -H "Authorization: Bearer $LLM_API_KEY"）
# 2. Elasticsearch 是否启动（测试：curl http://localhost:9200）
# 3. MySQL 是否启动（docker-compose ps mysql）
# 4. 后端日志是否有报错（docker-compose logs backend）
# 5. 环境变量是否正确加载（docker-compose exec backend env | grep LLM）

# ================================================================
# 联系方式
# ================================================================
# 如有问题，请查看项目文档：
# - README.md
# - DEPLOYMENT_GUIDE.md
# - CONFIGURATION_GUIDE.md（如果存在）

# ğŸš€ Ollama æœ¬åœ° Embedding éƒ¨ç½²æŒ‡å—

## ğŸ“‹ éƒ¨ç½²æ¦‚è¿°

**ç›®æ ‡**ï¼šä½¿ç”¨æœ¬åœ° Ollama æ›¿ä»£äº‘ç«¯ Embedding APIï¼Œå®ç°ï¼š
- âœ… å®Œå…¨å…è´¹ï¼ˆæ—  API è´¹ç”¨ï¼‰
- âœ… éšç§å®‰å…¨ï¼ˆæ•°æ®ä¸å‡ºæœ¬åœ°ï¼‰
- âœ… ç¨³å®šå¯é ï¼ˆä¸ä¾èµ–å¤–ç½‘ï¼‰

**æ¶æ„**ï¼š
```
Chatï¼ˆå›ç­”ï¼‰    â†’ ç«å±±å¼•æ“è±†åŒ… Seed1.6 Flashï¼ˆäº‘ç«¯ï¼‰
Embeddingï¼ˆå‘é‡ï¼‰ â†’ Ollama nomic-embed-textï¼ˆæœ¬åœ°ï¼‰
```

---

## ğŸ”§ é¦–æ¬¡éƒ¨ç½²æ­¥éª¤

### æ­¥éª¤ 1ï¼šæ¨é€ä»£ç åˆ° GitHub

```bash
# åœ¨æœ¬åœ°é¡¹ç›®ç›®å½•
git add .
git commit -m "feat: é›†æˆ Ollama æœ¬åœ° Embedding"
git push origin main
```

### æ­¥éª¤ 2ï¼šåœ¨æœåŠ¡å™¨ä¸Šæ‹‰å–ä»£ç 

```bash
# SSH ç™»å½•æœåŠ¡å™¨
ssh user@your-server-ip

# è¿›å…¥é¡¹ç›®ç›®å½•ï¼ˆå¦‚æœæ˜¯é¦–æ¬¡éƒ¨ç½²ï¼Œå…ˆ cloneï¼‰
cd /path/to/demo
# æˆ–é¦–æ¬¡ï¼šgit clone https://github.com/your-username/demo.git

# æ‹‰å–æœ€æ–°ä»£ç 
git pull origin main
```

### æ­¥éª¤ 3ï¼šå¯åŠ¨æ‰€æœ‰æœåŠ¡

```bash
# å¯åŠ¨æœåŠ¡ï¼ˆåŒ…æ‹¬æ–°å¢çš„ Ollamaï¼‰
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps
```

é¢„æœŸè¾“å‡ºï¼š
```
NAME                      STATUS
lingdang-mysql            Up
lingdang-elasticsearch    Up
lingdang-ollama           Up  â† æ–°å¢
lingdang-backend          Up
lingdang-frontend         Up
```

### æ­¥éª¤ 4ï¼šåˆå§‹åŒ– Ollama æ¨¡å‹ï¼ˆâ­ ä»…é¦–æ¬¡éœ€è¦ï¼‰

```bash
# æ‰§è¡Œåˆå§‹åŒ–è„šæœ¬
chmod +x init-ollama.sh
./init-ollama.sh
```

**è¯´æ˜**ï¼š
- è¯¥è„šæœ¬ä¼šä¸‹è½½ `nomic-embed-text` æ¨¡å‹ï¼ˆçº¦ 270MBï¼‰
- ä¸‹è½½æ—¶é—´ï¼š1-5 åˆ†é’Ÿï¼ˆå–å†³äºç½‘é€Ÿï¼‰
- **ä»…é¦–æ¬¡éƒ¨ç½²éœ€è¦æ‰§è¡Œ**
- æ¨¡å‹ä¿å­˜åœ¨ Docker Volume ä¸­ï¼Œåç»­æ— éœ€é‡å¤ä¸‹è½½

### æ­¥éª¤ 5ï¼šé‡å¯åç«¯æœåŠ¡

```bash
# é‡å¯åç«¯ä»¥åº”ç”¨æ–°é…ç½®
docker-compose restart backend

# æŸ¥çœ‹åç«¯æ—¥å¿—
docker-compose logs -f backend
```

### æ­¥éª¤ 6ï¼šéªŒè¯éƒ¨ç½²

```bash
# 1. å¥åº·æ£€æŸ¥
curl http://localhost:8080/api/health

# 2. æ£€æŸ¥ Ollama æœåŠ¡
curl http://localhost:11434/api/version

# 3. æŸ¥çœ‹å·²ä¸‹è½½çš„æ¨¡å‹
docker exec lingdang-ollama ollama list
```

é¢„æœŸçœ‹åˆ°ï¼š
```
NAME                    SIZE
nomic-embed-text:latest 270MB
```

---

## ğŸ”„ åç»­æ¨é€ï¼ˆæ— éœ€é‡æ–°éƒ¨ç½² Ollamaï¼‰

### ä»£ç æ›´æ–°æµç¨‹

```bash
# æœ¬åœ°ä¿®æ”¹ä»£ç å
git add .
git commit -m "your message"
git push origin main

# æœåŠ¡å™¨ä¸Šæ‹‰å–
ssh user@your-server-ip
cd /path/to/demo
git pull origin main

# ä»…é‡å¯åç«¯ï¼ˆæ— éœ€é‡å¯ Ollama/ES/MySQLï¼‰
docker-compose restart backend
```

**é‡è¦**ï¼š
- Ollama æ¨¡å‹å·²ä¿å­˜åœ¨ `ollama-data` Volume ä¸­
- åªè¦ä¸åˆ é™¤ Volumeï¼Œæ¨¡å‹æ°¸ä¹…ä¿ç•™
- åç»­éƒ¨ç½²**æ— éœ€**å†æ¬¡è¿è¡Œ `init-ollama.sh`

---

## ğŸ“Š é…ç½®è¯´æ˜

### .env æ–‡ä»¶é…ç½®ï¼ˆå·²è‡ªåŠ¨é…ç½®å¥½ï¼‰

```bash
# âœ… ä½¿ç”¨æœ¬åœ° Ollama
LLM_USE_OLLAMA_EMBEDDING=true
LLM_OLLAMA_BASE_URL=http://ollama:11434
LLM_EMBEDDING_MODEL=nomic-embed-text

# âœ… Chat ä»ä½¿ç”¨ç«å±±å¼•æ“
LLM_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
LLM_API_KEY=12df7044-2100-46fb-bcf5-cff4c5f051c8
LLM_CHAT_MODEL=ep-20250915111522-f87sr
```

### å¦‚ä½•åˆ‡æ¢å›äº‘ç«¯ Embedding

å¦‚æœå°†æ¥æƒ³åˆ‡æ¢å›äº‘ç«¯ï¼ˆå¦‚ OpenAIï¼‰ï¼š

```bash
# ä¿®æ”¹ .env
LLM_USE_OLLAMA_EMBEDDING=false
LLM_BASE_URL=https://api.openai.com/v1
LLM_API_KEY=sk-your-openai-key
LLM_EMBEDDING_MODEL=text-embedding-3-small

# é‡å¯åç«¯
docker-compose restart backend
```

---

## ğŸ§ª åŠŸèƒ½æµ‹è¯•

### æµ‹è¯• Embedding ç”Ÿæˆ

1. **ç™»å½• Studio**
   ```
   http://your-server-ip/studio/login
   ç”¨æˆ·åï¼šadmin
   å¯†ç ï¼šï¼ˆä½ é…ç½®çš„å¯†ç ï¼‰
   ```

2. **åˆ›å»ºå¹¶å‘å¸ƒæ–‡ç« **
   - ç‚¹å‡»ã€Œæ–°å»ºæ–‡ç« ã€
   - å¡«å†™æ ‡é¢˜ã€å†…å®¹
   - ç‚¹å‡»ã€Œå‘å¸ƒã€
   - è§‚å¯Ÿåç«¯æ—¥å¿—

3. **é¢„æœŸæ—¥å¿—**
   ```bash
   docker-compose logs backend | grep -i "ollama"
   ```
   åº”çœ‹åˆ°ï¼š
   ```
   INFO - ä½¿ç”¨ Ollama ç”Ÿæˆ embeddings: 15 ä¸ªæ–‡æœ¬
   INFO - Chunk ç´¢å¼•æˆåŠŸ: 15 ä¸ªç‰‡æ®µ
   ```

### æµ‹è¯• AI åŠ©æ‰‹

1. **è®¿é—®åŠ©æ‰‹é¡µé¢**
   ```
   http://your-server-ip/assistant
   ```

2. **æé—®æµ‹è¯•**
   - è¾“å…¥é—®é¢˜ï¼šã€Œæ–‡ç« ä¸­æåˆ°äº†ä»€ä¹ˆï¼Ÿã€
   - ç‚¹å‡»ã€Œæé—®ã€
   - åº”è¯¥è¿”å›å¸¦å¼•ç”¨çš„ç­”æ¡ˆ

---

## ğŸ“¦ Docker Volume ç®¡ç†

### æŸ¥çœ‹ Volumes

```bash
docker volume ls
```

åº”çœ‹åˆ°ï¼š
```
VOLUME NAME
demo_mysql-data
demo_es-data
demo_ollama-data  â† Ollama æ¨¡å‹å­˜å‚¨
```

### Volume å¤§å°

```bash
docker system df -v
```

### æ¸…ç† Volumeï¼ˆâš ï¸ æ…ç”¨ï¼‰

```bash
# åˆ é™¤æ‰€æœ‰æ•°æ®ï¼ˆåŒ…æ‹¬ Ollama æ¨¡å‹ï¼‰
docker-compose down -v

# ä»…åˆ é™¤ Ollama æ•°æ®
docker volume rm demo_ollama-data
```

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜ 1ï¼šOllama æœåŠ¡å¯åŠ¨å¤±è´¥

**ç—‡çŠ¶**ï¼š`docker-compose ps` æ˜¾ç¤º ollama çŠ¶æ€å¼‚å¸¸

**è§£å†³**ï¼š
```bash
# æŸ¥çœ‹æ—¥å¿—
docker-compose logs ollama

# é‡å¯æœåŠ¡
docker-compose restart ollama

# æ£€æŸ¥å¥åº·çŠ¶æ€
curl http://localhost:11434/api/version
```

### é—®é¢˜ 2ï¼šæ¨¡å‹ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶**ï¼š`init-ollama.sh` æ‰§è¡ŒæŠ¥é”™

**è§£å†³**ï¼š
```bash
# æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
docker exec -it lingdang-ollama ollama pull nomic-embed-text

# å¦‚æœç½‘ç»œé—®é¢˜ï¼Œå¯ä»¥å¤šæ¬¡é‡è¯•
# æˆ–ä½¿ç”¨ä»£ç†ï¼š
docker exec -it lingdang-ollama sh -c "HTTP_PROXY=http://proxy:port ollama pull nomic-embed-text"
```

### é—®é¢˜ 3ï¼šEmbedding ç”Ÿæˆå¤±è´¥

**ç—‡çŠ¶**ï¼šå‘å¸ƒæ–‡ç« æ—¶ç´¢å¼•ä»»åŠ¡å¤±è´¥

**æ£€æŸ¥æ¸…å•**ï¼š
```bash
# 1. æ£€æŸ¥ Ollama æ˜¯å¦è¿è¡Œ
curl http://localhost:11434/api/version

# 2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
docker exec lingdang-ollama ollama list

# 3. æ£€æŸ¥åç«¯é…ç½®
docker-compose exec backend env | grep LLM

# 4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯
docker-compose logs backend | tail -100
```

### é—®é¢˜ 4ï¼šåç«¯æ— æ³•è¿æ¥ Ollama

**ç—‡çŠ¶**ï¼šåç«¯æ—¥å¿—æ˜¾ç¤º "Connection refused"

**è§£å†³**ï¼š
```bash
# 1. ç¡®è®¤ Ollama æœåŠ¡åæ­£ç¡®
docker-compose ps ollama

# 2. æµ‹è¯•ç½‘ç»œè¿é€šæ€§
docker-compose exec backend curl http://ollama:11434/api/version

# 3. æ£€æŸ¥ docker-compose ç½‘ç»œ
docker network ls
docker network inspect demo_lingdang-network
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

| æŒ‡æ ‡ | Ollama (æœ¬åœ°) | OpenAI (äº‘ç«¯) | ç«å±±å¼•æ“ (äº‘ç«¯) |
|------|--------------|--------------|---------------|
| **Embedding é€Ÿåº¦** | 100-300ms | 200-500ms | 200-500ms |
| **æˆæœ¬** | å…è´¹ | $0.0001/1K tokens | æŒ‰è°ƒç”¨è®¡è´¹ |
| **éšç§** | å®Œå…¨æœ¬åœ° | äº‘ç«¯ä¼ è¾“ | äº‘ç«¯ä¼ è¾“ |
| **ä¾èµ–** | æœ¬åœ°èµ„æº | å¤–ç½‘ç¨³å®šæ€§ | å¤–ç½‘ç¨³å®šæ€§ |
| **è´¨é‡** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |

---

## ğŸ”„ å‡çº§ Ollama æ¨¡å‹

### æ›´æ¢ä¸ºå…¶ä»–æ¨¡å‹

å¦‚æœæƒ³ç”¨å…¶ä»– Embedding æ¨¡å‹ï¼š

```bash
# 1. ä¸‹è½½æ–°æ¨¡å‹ï¼ˆå¦‚ all-minilmï¼‰
docker exec lingdang-ollama ollama pull all-minilm

# 2. ä¿®æ”¹ .env
LLM_EMBEDDING_MODEL=all-minilm

# 3. é‡å¯åç«¯
docker-compose restart backend
```

### æ¨èæ¨¡å‹

| æ¨¡å‹åç§° | å¤§å° | æ”¯æŒè¯­è¨€ | æ¨èåº¦ |
|---------|------|---------|--------|
| **nomic-embed-text** | 270MB | ä¸­è‹±æ–‡ | â­â­â­â­â­ æ¨è |
| **all-minilm** | 45MB | è‹±æ–‡ä¸ºä¸» | â­â­â­ |
| **bge-large-zh** | 1.3GB | ä¸­æ–‡ä¼˜ç§€ | â­â­â­â­ |

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. é¦–æ¬¡éƒ¨ç½²

```bash
# å®Œæ•´æµç¨‹ï¼ˆé¦–æ¬¡ï¼‰
git pull
docker-compose up -d
./init-ollama.sh          # â­ ä»…é¦–æ¬¡
docker-compose restart backend
```

### 2. æ—¥å¸¸æ›´æ–°

```bash
# ä»£ç æ›´æ–°æµç¨‹ï¼ˆæ—¥å¸¸ï¼‰
git pull
docker-compose restart backend  # ä»…é‡å¯åç«¯
```

### 3. å¤‡ä»½ç­–ç•¥

```bash
# å¤‡ä»½ Ollama æ¨¡å‹ï¼ˆå¯é€‰ï¼‰
docker volume inspect demo_ollama-data

# å¦‚æœéœ€è¦è¿ç§»ï¼Œå¯ä»¥å¤‡ä»½æ•´ä¸ª Volume
docker run --rm -v demo_ollama-data:/data -v $(pwd):/backup \
  alpine tar czf /backup/ollama-backup.tar.gz -C /data .
```

---

## ğŸ¯ æ€»ç»“

### âœ… ä¼˜åŠ¿

1. **å®Œå…¨å…è´¹**ï¼šæ—  API è°ƒç”¨è´¹ç”¨
2. **éšç§å®‰å…¨**ï¼šæ•°æ®ä¸ç¦»å¼€æœåŠ¡å™¨
3. **ç¨³å®šå¯é **ï¼šä¸ä¾èµ–å¤–ç½‘ API
4. **æ€§èƒ½ä¼˜ç§€**ï¼šæœ¬åœ°æ¨ç†ï¼Œå»¶è¿Ÿä½

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **é¦–æ¬¡éƒ¨ç½²éœ€ä¸‹è½½æ¨¡å‹**ï¼ˆçº¦ 5 åˆ†é’Ÿï¼‰
2. **å¢åŠ èµ„æºå ç”¨**ï¼ˆ+2GB å†…å­˜ï¼Œ+1GB ç¡¬ç›˜ï¼‰
3. **åç»­éƒ¨ç½²æ— éœ€é‡å¤ä¸‹è½½**ï¼ˆVolume æŒä¹…åŒ–ï¼‰

### ğŸš€ ä¸‹ä¸€æ­¥

- éƒ¨ç½²å®Œæˆåæµ‹è¯•å‘å¸ƒæ–‡ç« 
- éªŒè¯ AI åŠ©æ‰‹æ£€ç´¢åŠŸèƒ½
- ç›‘æ§ Ollama æœåŠ¡çŠ¶æ€

---

Â© 2026 é“ƒé“›å¸ˆå…„å¤§æ¨¡å‹ - Ollama éƒ¨ç½²æŒ‡å—
